{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load excel file\n",
    "xls = pd.ExcelFile('KPMG_VI_New_raw_data_update_final.xlsx')\n",
    "\n",
    "#get list of sheets (review these first in excel to get an idea of what each contains)\n",
    "xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load specific sheets to their own dataframes\n",
    "df_trans = pd.read_excel(xls, sheet_name = 'Transactions')\n",
    "df_newcust = pd.read_excel(xls, sheet_name ='NewCustomerList')\n",
    "df_custdem = pd.read_excel (xls, sheet_name= 'CustomerDemographic')\n",
    "df_custadd = pd.read_excel (xls, sheet_name ='CustomerAddress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_trans.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There's a clear issue with our dataframe. Let's write a function to drop  these unnamned columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to drop unnamned columns\n",
    "def drop_columns(df):\n",
    "    df = df.drop([col for col in df.columns if 'Unnamed' in col], axis=1, inplace =True)\n",
    "    return df\n",
    "drop_columns(df_trans)\n",
    "drop_columns(df_newcust)\n",
    "drop_columns(df_custdem)\n",
    "drop_columns(df_custadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the transation table, customer demographic and address tables on customer ID\n",
    "whole1 = pd.merge(df_trans,df_custdem, on='customer_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the new merged table with the last, to form a single dataframe of old customers\n",
    "df_old = pd.merge(whole1,df_custadd,on='customer_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 19999\n",
      "Data columns (total 30 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   transaction_id                       20000 non-null  int64         \n",
      " 1   product_id                           20000 non-null  int64         \n",
      " 2   customer_id                          20000 non-null  int64         \n",
      " 3   transaction_date                     20000 non-null  int64         \n",
      " 4   online_order                         19640 non-null  float64       \n",
      " 5   order_status                         20000 non-null  object        \n",
      " 6   brand                                19803 non-null  object        \n",
      " 7   product_line                         19803 non-null  object        \n",
      " 8   product_class                        19803 non-null  object        \n",
      " 9   product_size                         19803 non-null  object        \n",
      " 10  list_price                           20000 non-null  float64       \n",
      " 11  standard_cost                        19803 non-null  float64       \n",
      " 12  product_first_sold_date              19803 non-null  float64       \n",
      " 13  first_name                           19997 non-null  object        \n",
      " 14  last_name                            19355 non-null  object        \n",
      " 15  gender                               19997 non-null  object        \n",
      " 16  past_3_years_bike_related_purchases  19997 non-null  float64       \n",
      " 17  DOB                                  19551 non-null  datetime64[ns]\n",
      " 18  job_title                            17603 non-null  object        \n",
      " 19  job_industry_category                16768 non-null  object        \n",
      " 20  wealth_segment                       19997 non-null  object        \n",
      " 21  deceased_indicator                   19997 non-null  object        \n",
      " 22  default                              18546 non-null  object        \n",
      " 23  owns_car                             19997 non-null  object        \n",
      " 24  tenure                               19551 non-null  float64       \n",
      " 25  address                              19968 non-null  object        \n",
      " 26  postcode                             19968 non-null  float64       \n",
      " 27  state                                19968 non-null  object        \n",
      " 28  country                              19968 non-null  object        \n",
      " 29  property_valuation                   19968 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(4), object(17)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_old.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id                            0\n",
       "product_id                                0\n",
       "customer_id                               0\n",
       "transaction_date                          0\n",
       "online_order                            360\n",
       "order_status                              0\n",
       "brand                                   197\n",
       "product_line                            197\n",
       "product_class                           197\n",
       "product_size                            197\n",
       "list_price                                0\n",
       "standard_cost                           197\n",
       "product_first_sold_date                 197\n",
       "first_name                                3\n",
       "last_name                               645\n",
       "gender                                    3\n",
       "past_3_years_bike_related_purchases       3\n",
       "DOB                                     449\n",
       "job_title                              2397\n",
       "job_industry_category                  3232\n",
       "wealth_segment                            3\n",
       "deceased_indicator                        3\n",
       "default                                1454\n",
       "owns_car                                  3\n",
       "tenure                                  449\n",
       "address                                  32\n",
       "postcode                                 32\n",
       "state                                    32\n",
       "country                                  32\n",
       "property_valuation                       32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Duplicate Rows based on all columns are :\n"
     ]
    }
   ],
   "source": [
    "#checking for duplicate data \n",
    "duplicateRowsDF = df_old[df_old.duplicated(keep=False)]\n",
    "print(\"All Duplicate Rows based on all columns are :\")\n",
    "#print(duplicateRowsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
